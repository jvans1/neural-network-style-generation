{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from importlib import reload\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import LBFGS, SGD\n",
    "import torch.nn as nn\n",
    "from __future__ import print_function\n",
    "import utils as U;reload(U)\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import copy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model and relevant indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activation_indexes = [ i for i, layer in enumerate(vgg.features) if type(layer) == nn.ReLU ]\n",
    "print(activation_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, weight, target):\n",
    "        super(ContentLoss, self).__init__()        \n",
    "        self.target = target.detach()\n",
    "        self.weight = weight\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.loss = self.loss_fn(input, self.target)\n",
    "        self.output = input.clone()\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, retain_graph=True):\n",
    "        self.loss.backward(retain_graph=retain_graph)\n",
    "        return self.loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        batch_size, height, width, chan = input.size()\n",
    "        flattened_channels = input.view(batch_size * height, width * chan)\n",
    "        g_matrix = torch.mm(flattened_channels, flattened_channels.t())\n",
    "        return g_matrix.div(flattened_channels.nelement())\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, weight, target):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = target.detach() * weight\n",
    "        self.weight = weight\n",
    "        self.gram = GramMatrix()\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.output = input.clone()\n",
    "        self.G = self.gram(input)\n",
    "        self.G.mul_(self.weight)\n",
    "        self.loss = self.loss_fn(self.G, self.target)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, retain_graph=True):\n",
    "        self.loss.backward(retain_graph=retain_graph)\n",
    "        return self.loss     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Style Transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(cnn, content_layers, style_layers, content_image, style_image):\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "    model = nn.Sequential()\n",
    "    cnn = copy.deepcopy(cnn).cuda()\n",
    "    gram = GramMatrix()\n",
    "    style_indexes = style_layers.keys()\n",
    "    content_indexes = content_layers.keys()\n",
    "    for index, layer in enumerate(cnn.features):\n",
    "        layer_set = False            \n",
    "        if type(layer) is nn.ReLU:\n",
    "            layer_set = True\n",
    "            model.add_module(\"layer_{}_relu\".format(index), layer)\n",
    "            \n",
    "            if  index in style_indexes:\n",
    "                style_target = model(style_image.unsqueeze(0)).clone()\n",
    "                style_loss = StyleLoss(style_layers[index], gram(style_target))\n",
    "                style_losses.append(style_loss)\n",
    "                model.add_module(\"layer_{}_style_loss_relu\".format(index), style_loss)\n",
    "            \n",
    "            if index in content_indexes:\n",
    "                content_target = model(content_image.unsqueeze(0)).clone()\n",
    "                content_loss = ContentLoss(content_layers[index], content_target)\n",
    "                content_losses.append(content_loss)\n",
    "                model.add_module(\"layer_{}_content_loss_relu\".format(index), content_loss)           \n",
    "\n",
    "        if type(layer) is nn.MaxPool2d:\n",
    "            #replace max pooling with avg pooling to retain more information\n",
    "            layer_set = True\n",
    "            avg_pool = nn.AvgPool2d(kernel_size=layer.kernel_size, stride=layer.stride, padding = layer.padding)\n",
    "            model.add_module(\"layer_{}\".format(index), avg_pool)\n",
    "            \n",
    "        if not layer_set:\n",
    "            model.add_module(\"layer_{}\".format(index), layer)\n",
    "    model = model.cuda()\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    return model, content_losses, style_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epochs(mmmodel, count, img, optimizer, s_losses, c_losses, print_every=100):\n",
    "    elapsed_epochs = 0\n",
    "    for i in range(count):\n",
    "        img.data.clamp_(0,1)\n",
    "        mmmodel.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        elapsed_epochs += 1\n",
    "        prediction = img.unsqueeze(0)\n",
    "        \n",
    "        mmmodel(prediction)\n",
    "        \n",
    "        s_loss = sum([ s.backward() for s in s_losses ])\n",
    "        c_loss = sum([ c.backward() for c in c_losses ])\n",
    "#\n",
    "        optimizer.step()\n",
    "        style_loss =  s_loss.data[0]\n",
    "        content_loss = c_loss.data[0]\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(\"Epoch #{} Content Loss: {} Style Loss: {} Total Loss: {}\".format(str(i + 1000), content_loss, style_loss, content_loss + style_loss ))\n",
    "    img.data.clamp_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(starting_img, lr=1):\n",
    "    img_param = nn.Parameter(starting_img)\n",
    "    img_param = img_param.cuda().clone().detach()\n",
    "    img_param.requires_grad = True\n",
    "    optimizer = SGD([img_param], lr=lr)\n",
    "    return img_param, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_layers = {\n",
    "    1: 1,\n",
    "    3: 1,\n",
    "    6: 1,\n",
    "    8: 1,\n",
    "    11: 1\n",
    "}\n",
    "\n",
    "style_layers = {\n",
    "    1: 1000,\n",
    "    3: 1200,\n",
    "    6: 1400,\n",
    "    8: 2200,\n",
    "    11: 3500\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "unloader = ToPILImage()\n",
    "def unload(img):\n",
    "    img = img.data\n",
    "    img = img.clone().cpu()\n",
    "    img = unloader(img)\n",
    "    return img\n",
    "\n",
    "def show_results(content_image, style_image, img):\n",
    "    content_img = unload(content_image)\n",
    "    style_img = unload(style_image)\n",
    "    result_img = unload(img)\n",
    "    \n",
    "    f, axis = plt.subplots(1,3)\n",
    "    f.set_size_inches(20, 5)\n",
    "    axis[0].imshow(content_img)\n",
    "    axis[1].imshow(style_img)\n",
    "    axis[2].imshow(result_img)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style_image  = Variable(U.get_image(9, 84)).cuda()\n",
    "content_image = Variable(U.get_image(4, None, 112)).cuda()\n",
    "\n",
    "model, c_losses, s_losses = build_model(vgg, content_layers, style_layers, content_image, style_image)\n",
    "img_param, optimizer = build_optimizer(content_image.data, lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1000 Content Loss: 0.8291915655136108 Style Loss: 0.29741787910461426 Total Loss: 1.126609444618225\n"
     ]
    }
   ],
   "source": [
    "run_epochs(model, 5000, img_param, optimizer, s_losses, c_losses, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
